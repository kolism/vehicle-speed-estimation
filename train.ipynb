{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.optim as optim\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE cuda\n"
     ]
    }
   ],
   "source": [
    "# check if cuda is available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"DEVICE\",device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 0     # model version\n",
    "in_c = 2  # number of input channels\n",
    "num_c = 1 # number of classes to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The optical flow input will look like this\n",
    "of = torch.randn(1,2,1164,874)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "model = EfficientNet.from_pretrained(f'efficientnet-b{v}', in_channels=in_c, num_classes=num_c)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The output of the model will look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005008313804864883"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "of = of.to(device)\n",
    "model(of).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory with the optical flow images\n",
    "of_dir = 'C:/Users/Cana/Documents/GitHub/pyslam/outFlow0'\n",
    "# labels as txt file\n",
    "labels_f = 'C:/Users/Cana/Documents/GitHub/pyslam/labelsPITCH.txt'\n",
    "model_file='C:/Users/Cana/Documents/GitHub/pyslam/outputPITCH.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OFDataset(Dataset):\n",
    "    def __init__(self, of_dir, label_f):\n",
    "        self.len = len(list(Path(of_dir).glob('*.npy')))\n",
    "        print(\"len\",self.len)\n",
    "        self.of_dir = of_dir\n",
    "        self.label_file = open(label_f).readlines()\n",
    "        #print(\"selflavelfike\",self.label_file)\n",
    "    def __len__(self): return self.len\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        of_array = np.load(Path(self.of_dir)/f'{idx}.npy')\n",
    "  \n",
    "     \n",
    "     \n",
    "        of_tensor = torch.squeeze(torch.tensor(of_array))\n",
    "      \n",
    "        label = float(self.label_file[idx].split()[0])\n",
    "        #print(\"label\",label)\n",
    "        return [of_tensor, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len 5995\n",
      "DS1 0.03149205029088487\n"
     ]
    }
   ],
   "source": [
    "ds = OFDataset(of_dir, labels_f)\n",
    "print(\"DS1\",ds[0][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80% of data for training\n",
    "# 20% of data for validation\n",
    "train_split = .9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_size = len(ds)\n",
    "indices = list(range(ds_size))\n",
    "split = int(np.floor(train_split * ds_size))\n",
    "train_idx, val_idx = indices[:split], indices[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample = ds[3]\n",
    "assert type(sample[0]) == torch.Tensor\n",
    "assert type(sample[1]) == float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(val_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_cores = multiprocessing.cpu_count()\n",
    "cpu_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds <__main__.OFDataset object at 0x0000027855DCDAC0>\n",
      "train_dl <torch.utils.data.dataloader.DataLoader object at 0x0000027855DEA9D0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"ds\",ds)\n",
    "train_dl = DataLoader(ds, batch_size=3, sampler=train_sampler, num_workers=0)\n",
    "val_dl = DataLoader(ds, batch_size=3, sampler=val_sampler, num_workers=0)\n",
    "print(\"train_dl\",train_dl)\n",
    "\n",
    "state = torch.load(model_file)\n",
    "model.load_state_dict(state.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "log_train_steps = 1\n",
    "loops_per_epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "opt = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch $0\n",
      "Train i: 0\n",
      "Train i: 1\n",
      "Train i: 2\n",
      "Train i: 3\n",
      "Train i: 4\n",
      "Train i: 5\n",
      "Train i: 6\n",
      "Pred tensor([0.0561, 0.0329, 0.0539], device='cuda:0')=tensor([0.0555, 0.0431, 0.0630], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "Val j: 0\n",
      "Val j: 1\n",
      "Val j: 2\n",
      "Val j: 3\n",
      "Val j: 4\n",
      "Val j: 5\n",
      "Val j: 6\n",
      "0: 0.0003658866335172206\n",
      "Epoch $1\n",
      "Train i: 0\n",
      "Train i: 1\n",
      "Train i: 2\n",
      "Train i: 3\n",
      "Train i: 4\n",
      "Train i: 5\n",
      "Train i: 6\n",
      "Pred tensor([0.0110, 0.0000, 0.0555], device='cuda:0')=tensor([0.0076, 0.0094, 0.0250], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "Val j: 0\n",
      "Val j: 1\n",
      "Val j: 2\n",
      "Val j: 3\n",
      "Val j: 4\n",
      "Val j: 5\n",
      "Val j: 6\n",
      "1: 0.0009279018850065768\n",
      "Epoch $2\n",
      "Train i: 0\n",
      "Train i: 1\n",
      "Train i: 2\n",
      "Train i: 3\n",
      "Train i: 4\n",
      "Train i: 5\n",
      "Train i: 6\n",
      "Pred tensor([0.0000, 0.0611, 0.0119], device='cuda:0')=tensor([0.0030, 0.0278, 0.0034], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "Val j: 0\n",
      "Val j: 1\n",
      "Val j: 2\n",
      "Val j: 3\n",
      "Val j: 4\n",
      "Val j: 5\n",
      "Val j: 6\n",
      "2: 0.00013951852452009916\n",
      "Epoch $3\n",
      "Train i: 0\n",
      "Train i: 1\n",
      "Train i: 2\n",
      "Train i: 3\n",
      "Train i: 4\n",
      "Train i: 5\n",
      "Train i: 6\n",
      "Pred tensor([0.0000, 0.0321, 0.0195], device='cuda:0')=tensor([0.0366, 0.0201, 0.0095], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "Val j: 0\n",
      "Val j: 1\n",
      "Val j: 2\n",
      "Val j: 3\n",
      "Val j: 4\n",
      "Val j: 5\n",
      "Val j: 6\n",
      "3: 0.00034878894803114235\n",
      "Epoch $4\n",
      "Train i: 0\n",
      "Train i: 1\n",
      "Train i: 2\n",
      "Train i: 3\n",
      "Train i: 4\n",
      "Train i: 5\n",
      "Train i: 6\n",
      "Pred tensor([0.0077, 0.0313, 0.0000], device='cuda:0')=tensor([0.0189, 0.0230, 0.0239], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "Val j: 0\n",
      "Val j: 1\n",
      "Val j: 2\n",
      "Val j: 3\n",
      "Val j: 4\n",
      "Val j: 5\n",
      "Val j: 6\n",
      "4: 0.0016584382392466068\n",
      "Epoch $5\n",
      "Train i: 0\n",
      "Train i: 1\n",
      "Train i: 2\n",
      "Train i: 3\n",
      "Train i: 4\n",
      "Train i: 5\n",
      "Train i: 6\n",
      "Pred tensor([0.0325, 0.0000, 0.0000], device='cuda:0')=tensor([0.0198, 0.0396, 0.0115], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "Val j: 0\n",
      "Val j: 1\n",
      "Val j: 2\n",
      "Val j: 3\n",
      "Val j: 4\n",
      "Val j: 5\n",
      "Val j: 6\n",
      "5: 0.0023555743973702192\n",
      "Epoch $6\n",
      "Train i: 0\n",
      "Train i: 1\n",
      "Train i: 2\n",
      "Train i: 3\n",
      "Train i: 4\n",
      "Train i: 5\n",
      "Train i: 6\n",
      "Pred tensor([0.0295, 0.0484, 0.0539], device='cuda:0')=tensor([0.0356, 0.0342, 0.0458], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "Val j: 0\n",
      "Val j: 1\n",
      "Val j: 2\n",
      "Val j: 3\n",
      "Val j: 4\n",
      "Val j: 5\n",
      "Val j: 6\n",
      "6: 0.0005467899609357119\n",
      "Epoch $7\n",
      "Train i: 0\n",
      "Train i: 1\n",
      "Train i: 2\n",
      "Train i: 3\n",
      "Train i: 4\n",
      "Train i: 5\n",
      "Train i: 6\n",
      "Pred tensor([0.0328, 0.0000, 0.0212], device='cuda:0')=tensor([0.0306, 0.0180, 0.0205], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "Val j: 0\n",
      "Val j: 1\n",
      "Val j: 2\n",
      "Val j: 3\n",
      "Val j: 4\n",
      "Val j: 5\n",
      "Val j: 6\n",
      "7: 0.00038392769056372344\n",
      "Epoch $8\n",
      "Train i: 0\n",
      "Train i: 1\n",
      "Train i: 2\n",
      "Train i: 3\n",
      "Train i: 4\n",
      "Train i: 5\n",
      "Train i: 6\n",
      "Pred tensor([0.0197, 0.0125, 0.0194], device='cuda:0')=tensor([0.0436, 0.0328, 0.0370], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "Val j: 0\n",
      "Val j: 1\n",
      "Val j: 2\n",
      "Val j: 3\n",
      "Val j: 4\n",
      "Val j: 5\n",
      "Val j: 6\n",
      "8: 0.0003605979436542839\n",
      "Epoch $9\n",
      "Train i: 0\n",
      "Train i: 1\n",
      "Train i: 2\n",
      "Train i: 3\n",
      "Train i: 4\n",
      "Train i: 5\n",
      "Train i: 6\n",
      "Pred tensor([0.0626, 0.0191, 0.0125], device='cuda:0')=tensor([ 0.0172, -0.0559, -0.0157], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "Val j: 0\n",
      "Val j: 1\n",
      "Val j: 2\n",
      "Val j: 3\n",
      "Val j: 4\n",
      "Val j: 5\n",
      "Val j: 6\n",
      "9: 0.0013044043444097042\n",
      "Epoch $10\n",
      "Train i: 0\n",
      "Train i: 1\n",
      "Train i: 2\n",
      "Train i: 3\n",
      "Train i: 4\n",
      "Train i: 5\n",
      "Train i: 6\n",
      "Pred tensor([0.0000, 0.0207, 0.0117], device='cuda:0')=tensor([0.0445, 0.0126, 0.0346], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "Val j: 0\n",
      "Val j: 1\n",
      "Val j: 2\n",
      "Val j: 3\n",
      "Val j: 4\n",
      "Val j: 5\n",
      "Val j: 6\n",
      "10: 0.0008377412450499833\n",
      "Epoch $11\n",
      "Train i: 0\n",
      "Train i: 1\n",
      "Train i: 2\n",
      "Train i: 3\n",
      "Train i: 4\n",
      "Train i: 5\n",
      "Train i: 6\n",
      "Pred tensor([0.0588, 0.0065, 0.0391], device='cuda:0')=tensor([0.0268, 0.0128, 0.0257], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "Val j: 0\n",
      "Val j: 1\n",
      "Val j: 2\n",
      "Val j: 3\n",
      "Val j: 4\n",
      "Val j: 5\n",
      "Val j: 6\n",
      "11: 0.0017957402160391212\n",
      "Epoch $12\n",
      "Train i: 0\n",
      "Train i: 1\n",
      "Train i: 2\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(f'Epoch ${epoch}')\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, sample in enumerate(train_dl):\n",
    "        of_tensor = sample[0].cuda()       \n",
    "        label = sample[1].float().cuda()\n",
    "        #print(\"Labelx\",label)\n",
    "        opt.zero_grad()\n",
    "        pred = torch.squeeze(model(of_tensor))   \n",
    "        loss = criterion(pred, label)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        print(f'Train i: {i}')\n",
    "        if(i>=loops_per_epoch):\n",
    "            break\n",
    "    print(f'Pred {label}={pred}')\n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for j, val_sample in enumerate(val_dl):\n",
    "            print(f'Val j: {j}')\n",
    "            of_tensor = val_sample[0].cuda()\n",
    "            label = val_sample[1].float().cuda()\n",
    "            pred = torch.squeeze(model(of_tensor))           \n",
    "            loss = criterion(pred, label)\n",
    "            val_losses.append(loss)\n",
    "            if(j>=loops_per_epoch):\n",
    "                break\n",
    "        print(f'{epoch}: {sum(val_losses)/len(val_losses)}')\n",
    "    torch.save(model, model_file)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e5d09d59fff3afbd6512f5df5a4d79ce0c9bc0993d966cbaf304a501e5e77b84"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit ('python39': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
